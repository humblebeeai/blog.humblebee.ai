{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to the Humblebee AI Blog","text":""},{"location":"release-notes/","title":"\ud83d\udccc Release Notes","text":""},{"location":"release-notes/#v011-250824-2025-08-24","title":"v0.1.1-250824 (2025-08-24)","text":""},{"location":"release-notes/#whats-changed","title":"What's Changed","text":""},{"location":"release-notes/#documentation","title":"\ud83d\udcdd Documentation","text":"<ul> <li>feat: Update author avatar, add first blog post, and enhance document\u2026 by @bybatkhuu in https://github.com/humblebeeai/docs.humblebee-blog/pull/1</li> </ul>"},{"location":"release-notes/#new-contributors","title":"New Contributors","text":"<ul> <li>@bybatkhuu made their first contribution in https://github.com/humblebeeai/docs.humblebee-blog/pull/1</li> </ul> <p>Full Changelog: https://github.com/humblebeeai/docs.humblebee-blog/compare/v0.1.0-250625...v0.1.1-250824</p>"},{"location":"release-notes/#v010-250625-2025-06-25","title":"v0.1.0-250625 (2025-06-25)","text":"<p>Full Changelog: https://github.com/humblebeeai/docs.humblebee-blog/commits/v0.1.0-250625</p>"},{"location":"blog/","title":"\u270f\ufe0f Blog","text":"<p>This is the blog page. It will list all the blog posts.</p>","tags":["blog"]},{"location":"blog/2025/11/08/tailscale---one-tool-less-infrastructure/","title":"Tailscale - One Tool, Less Infrastructure","text":"<p>You have multiple devices like a laptop, a production server, maybe an edge server. Accessing your work devices from outside your network usually requires port forwarding, dynamic DNS services, or a VPN, this usually raises security concerns as setting those up requires your public IP to be exposed.</p> <p>Tailscale makes this simple. Install it on your devices and sign in. They can now reach each other securely from anywhere.</p>","tags":["blog","VPN","Network","Tailscale"]},{"location":"blog/2025/11/08/tailscale---one-tool-less-infrastructure/#what-is-tailscale","title":"What Is Tailscale?","text":"<p>Tailscale creates a secure network between your devices. Your devices connect directly to each other (peer-to-peer), not through a central server. This means faster speeds and no single point of failure.</p> <p>Install it on your laptop and work server. Sign in with your Google account on both. Now you can <code>ssh servername</code> from a coffee shop and it connects like they're on the same local network.</p> <p>No port forwarding. No complex configs. No networking knowledge required.</p> <p>Beyond being a VPN that actually works, Tailscale replaces several tools: dynamic DNS for device names, ngrok for sharing localhost, and firewall rules for access control.</p>","tags":["blog","VPN","Network","Tailscale"]},{"location":"blog/2025/11/08/tailscale---one-tool-less-infrastructure/#access-devices-by-name","title":"Access Devices by Name","text":"<p>Replaces: Custom DNS servers, memorizing IPs, updating hosts files</p> <p>Setting up Pi-hole or bind9 just to give your devices readable names? Updating DNS records every time you add a machine? Memorizing <code>192.168.1.142</code> because you're too lazy to configure it properly?</p> <p>MagicDNS does this automatically:</p> <p><code>ssh servername</code></p> <p>Every device gets a name. No server to maintain, no records to update, no IPs to remember.</p> <p></p> <p>Type <code>http://nas</code> to reach your NAS. Type <code>ssh work-laptop</code> to reach your work machine. The names just work.</p>","tags":["blog","VPN","Network","Tailscale"]},{"location":"blog/2025/11/08/tailscale---one-tool-less-infrastructure/#share-local-services-publicly","title":"Share Local Services Publicly","text":"<p>Replaces: ngrok, localtunnel, port forwarding</p> <p>You know the drill with ngrok: random URLs that change every time you restart, rate limits on the free tier, paying $8/month if you want a stable subdomain.</p> <p>Tailscale Funnel:</p> <p><code>tailscale funnel 3000</code></p> <p>Your local dev server is now at <code>https://my-laptop.tailnet-name.ts.net</code>. Permanent URL. Free. No rate limits.</p> <p>Testing webhooks from Stripe? Demoing a feature to a client? Running a side project on your work server? One command handles it.</p> <p>If you want to share something with just your team (not the whole internet):</p> <p><code>tailscale serve 3000</code></p> <p>Same thing, but only people on your Tailscale network can access it.</p> <p>\ud83d\udcda Funnel examples \u00b7 Command reference</p>","tags":["blog","VPN","Network","Tailscale"]},{"location":"blog/2025/11/08/tailscale---one-tool-less-infrastructure/#control-who-reaches-what","title":"Control Who Reaches What","text":"<p>Replaces: Firewall rules, iptables configs, security groups</p> <p>SSHing into each server to configure iptables. Documenting which ports are open where. Breaking production because you fat-fingered a rule at 2 AM.</p> <p>Tailscale ACLs are just a JSON file:</p> <pre><code>{\n  \"grants\": [\n    {\n      \"src\": [\"contractor@email.com\"],\n      \"dst\": [\"tag:staging\"],\n      \"ip\": [\"5432\"]\n    }\n  ]\n}\n</code></pre> <p>This contractor can access your staging database (port 5432). Nothing else. When they're done, delete the line. No leftover rules hiding on some forgotten server.</p> <p>Team-based access:</p> <pre><code>{\n  \"grants\": [\n    {\n      \"src\": [\"group:sre\"],\n      \"dst\": [\"tag:prod\"],\n      \"ip\": [\"22\"]\n    }\n  ],\n  \"groups\": {\n    \"group:sre\": [\"alice@company.com\", \"bob@company.com\"]\n  }\n}\n</code></pre> <p>Your SRE team can SSH into production. Everyone else can't. Alice leaves the company? Remove her email. Policy updates everywhere instantly.</p> <p>No more SSH key distribution across 50 servers. No more \"wait, which subnet is staging?\" No more firewall rules that you're afraid to touch because nobody remembers why they exist.</p> <p>\ud83d\udcda ACL examples \u00b7 Grant examples</p>","tags":["blog","VPN","Network","Tailscale"]},{"location":"blog/2025/11/08/tailscale---one-tool-less-infrastructure/#run-services-anywhere","title":"Run Services Anywhere","text":"<p>Replaces: Load balancers, DNS updates, hardcoded hostnames</p> <p>You're running a database on <code>db-server-01</code>. That hostname is hardcoded in your configs. Server dies, you spin up <code>db-server-02</code>, and now you're doing find-replace across your codebase at midnight.</p> <p>Or you set up HAProxy. Configure health checks. Set up DNS. Maintain yet another piece of infrastructure.</p> <p>Tailscale Services:</p> <p><code>tailscale serve --service=svc:postgres-main --tcp 5432 localhost:5432</code></p> <p>Your database is now at <code>postgres-main.corp.ts.net</code>. Server dies? Run the same command on a new machine. The DNS name stays the same. Your apps reconnect automatically.</p> <p>Multi-region example:</p> <pre><code># Primary (US)\ntailscale serve --service=svc:db-primary --tcp 5432 localhost:5432\n\n# Replica (EU)\ntailscale serve --service=svc:db-replica --tcp 5432 localhost:5432\n</code></pre> <p>Apps write to <code>db-primary.corp.ts.net</code> and read from <code>db-replica.corp.ts.net</code>. Primary goes down? Promote the replica and re-advertise it as primary. No config changes needed anywhere.</p> <p>You can also control who accesses these services:</p> <pre><code>{\n  \"grants\": [\n    {\n      \"src\": [\"group:backend-team\"],\n      \"dst\": [\"svc:postgres-main\"],\n      \"ip\": [\"5432\"]\n    }\n  ]\n}\n</code></pre> <p>Backend team can reach the database. Frontend team gets blocked automatically.</p> <p>\ud83d\udcda Services docs \u00b7 Configuration guide</p>","tags":["blog","VPN","Network","Tailscale"]},{"location":"blog/2025/11/08/tailscale---one-tool-less-infrastructure/#no-more-traditional-vpns","title":"No More Traditional VPNs","text":"<p>Central VPN server that's a bottleneck and single point of failure. Slow speeds because everything routes through one location. Complex setup with certificates and subnet planning. \"VPN is down\" means everyone's locked out.</p> <p>Tailscale creates direct peer-to-peer connections. Your laptop talks directly to your server. No central bottleneck. Uses WireGuard encryption without the WireGuard complexity.</p> <p>Setup is install, sign in, done. Takes 2 minutes. Devices can still connect to each other even if Tailscale's coordination server has issues (it handles the initial introduction, then gets out of the way).</p>","tags":["blog","VPN","Network","Tailscale"]},{"location":"blog/2025/11/08/tailscale---one-tool-less-infrastructure/#why-this-matters","title":"Why This Matters","text":"<p>Networking tools usually force a choice: simple but insecure, or secure but complex. Port forwarding is easy but leaves your services exposed. VPNs are secure but a pain to set up and maintain.</p> <p>Tailscale doesn't make you choose. It's secure by default (WireGuard encryption, identity-based auth, ACL policies) and actually easier to use than other alternatives.</p> <p>You're replacing DNS servers, ngrok subscriptions, firewall configurations, VPN infrastructure, and SSH key management with one tool that takes 2 minutes to set up.</p>","tags":["blog","VPN","Network","Tailscale"]},{"location":"blog/2025/11/08/tailscale---one-tool-less-infrastructure/#get-started","title":"Get Started","text":"<p>Download from tailscale.com/download. Install on two devices. Sign in. They'll find each other automatically.</p> <pre><code># See your devices\ntailscale status\n\n# SSH into another machine\nssh machine-name\n\n# Share something publicly\ntailscale funnel 8080\n\n# Share with just your team\ntailscale serve 8080\n</code></pre> <p>Two minutes to set up. Zero maintenance required.</p>","tags":["blog","VPN","Network","Tailscale"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/","title":"LiveKit - One Platform, Real-Time Everything","text":"<p>Video calls need one platform. Live streaming needs another. Voice AI agents need a third. Computer vision processing? That's a fourth vendor. Managing robots remotely? Good luck finding something that works. LiveKit replaces all of them. One SDK for voice agents, video streaming, vision AI, and robot control. Sub-100ms latency across the board.</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#what-is-livekit","title":"What Is LiveKit?","text":"<p>LiveKit is an open-source real-time communication platform built on WebRTC. It's not just another video calling API - it's infrastructure for anything that needs to move audio, video, or data between users and AI agents in real-time.</p> <p>Voice AI that talks to customers. Video streaming from robots. AI analyzing live camera feeds. Different problems, all in the same session, all using the same platform.</p> <p>No juggling multiple services. No vendor lock-in. No reinventing WebRTC from scratch.</p> <p>Beyond video calls, LiveKit replaces: dedicated streaming CDNs, voice AI infrastructure, robotics communication stacks, and complex WebRTC implementations.</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#how-livekit-works","title":"How LiveKit Works","text":"<p>The Stack:</p> <ul> <li>LiveKit Server - WebRTC SFU (Selective Forwarding Unit) that routes media streams. Self-host or use LiveKit Cloud.</li> <li>Rooms - Where participants connect. Users, AI agents, robots - all join the same room to communicate.</li> <li>Participants - Anything connected to a room. Browser clients, mobile apps, backend agents, IoT devices.</li> <li>Tracks - Audio, video, or data streams published by participants. Subscribe to tracks you want to receive.</li> </ul> <p>Simple flow:</p> <ol> <li>Server creates a room</li> <li>Participants join with access tokens</li> <li>Publish tracks (camera, mic, screen, data)</li> <li>Subscribe to other participants' tracks</li> <li>Server forwards media directly between participants</li> </ol> <pre><code># Backend: Create room and generate token\nroom = await livekit_api.room.create_room(\"my-room\")\ntoken = create_token(identity=\"user1\", room_name=\"my-room\")\n\n# Client: Join and publish\nroom = Room()\nawait room.connect(url, token)\nawait room.local_participant.publish_track(camera_track)\n</code></pre> <p>No central transcoding = Server doesn't decode/re-encode video. Server just forwards packets directly. Low latency, scales horizontally.</p> <p>Agent workers sit between server and AI models. Join rooms as participants, process audio/video, call AI APIs, publish responses back.</p> <p>\ud83d\udcda Architecture overview</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#build-voice-ai-that-actually-works","title":"Build Voice AI That Actually Works","text":"<p>Replaces: Custom STT-LLM-TTS pipelines, latency-prone API chains, fragile state management</p> <p>You know the drill with voice AI: chain together separate APIs for speech-to-text, your LLM, and text-to-speech. Each step adds 300ms of latency. User interrupts mid-sentence? Your state management explodes. Your app crashes overnight because the TTS API went down.</p> <p>LiveKit Agents:</p> <pre><code>from livekit.agents import VoiceAssistant\nfrom livekit.plugins import openai, deepgram, elevenlabs\n\nassistant = VoiceAssistant(\n    stt=deepgram.STT(),\n    llm=openai.LLM(model=\"gpt-4\"),\n    tts=elevenlabs.TTS(),\n)\nassistant.start(room)\n</code></pre> <p>Your voice AI is live. Natural interruptions handled automatically. Turn detection using transformer models. Multi-agent workflows when you need them.</p> <p>ChatGPT's Advanced Voice Mode? Built on LiveKit. Millions of users, every day.</p> <p>Building a phone-based customer service bot? Restaurant ordering system? Medical triage assistant? One framework, production-ready from day one.</p> <p>\ud83d\udcda Voice AI quickstart \u00b7 Agent examples</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#stream-video-without-the-video-streaming-complexity","title":"Stream Video Without the Video Streaming Complexity","text":"<p>Replaces: Traditional CDNs, HLS delays, separate chat infrastructure</p> <p>Setting up HLS streaming: 10-30 seconds of latency, viewers see different things at different times, separate WebSocket server for chat, separate RTMP ingest pipeline, separate viewer analytics.</p> <p>LiveKit's WebRTC Streaming:</p> <pre><code>room = Room()\nawait room.connect(url, token)\n\n# Start streaming\nawait room.local_participant.publish_track(video_track)\n</code></pre> <p>Every viewer is within 250ms of real-time. They all see the same frame at the same moment. Two-way audio/video built-in - any viewer can become a streamer instantly. Chat and data messages included. Record sessions with one API call.</p> <p>\ud83d\udcda Livestreaming docs \u00b7 Recording guide</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#control-robots-from-anywhere","title":"Control Robots From Anywhere","text":"<p>Replaces: Custom video streaming solutions, high-latency feeds, unreliable connections</p> <p>Your robots have cameras. Sensors. Microphones. You need that data streamed to operators in real-time, or processed by AI in the cloud, or both. Building this from scratch means dealing with video encoding, network resilience, secure streaming, and somehow doing it all with under 100ms latency.</p> <p>LiveKit for Robotics:</p> <pre><code># On the robot\ntrack = VideoTrack.from_camera()\nroom.local_participant.publish_track(track)\n\n# Send sensor data\nawait room.local_participant.publish_data(\n    sensor_readings,\n    destination_identities=[\"operator\"]\n)\n</code></pre> <p>Stream from thousands of robots. Route specific feeds to operators. Process video with AI models in real-time. All over unreliable mobile networks - WebRTC handles packet loss, adapts bitrate automatically.</p> <p>Agricultural robots working in fields with spotty connection? WebRTC stays connected where traditional streaming dies.</p> <p>\ud83d\udcda Robotics use case \u00b7 Data streams guide</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#mix-humans-and-ai-in-the-same-call","title":"Mix Humans and AI in the Same Call","text":"<p>Replaces: Separate platforms, awkward transfers, repeating your problem three times</p> <p>Customer calls. AI greets and troubleshoots. Needs billing help. Transfer. Customer explains issue again. Needs technical support. Transfer again. Explain everything from scratch. Again.</p> <p>LiveKit Multi-Agent Workflows:</p> <pre><code>class FrontlineAgent(Agent):\n    @function_tool()\n    async def transfer_to_billing(self):\n        return BillingAgent(chat_ctx=self.chat_ctx)\n\n    @function_tool()\n    async def escalate_to_human(self):\n        return HumanAgent(chat_ctx=self.chat_ctx)\n\n# chat_ctx = full conversation history passes to next agent\n</code></pre> <p>AI greeter \u2192 Billing AI \u2192 Human specialist. Same call. Full context preserved. No repeating. Each agent knows what previous agents discussed.</p> <p>Examples: Medical triage (symptoms \u2192 specialist), drive-thru ordering (greeter \u2192 order taker \u2192 payment), call centers (AI screens \u2192 human closes).</p> <p>\ud83d\udcda Multi-agent workflows \u00b7 Agent handoff examples</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#actually-multimodal-ai","title":"Actually Multimodal AI","text":"<p>Replaces: Voice-only AI, separate video processing pipelines</p> <p>Your AI should see what users see. Point a camera at a product, ask questions about it. Share your screen, get help with what you're looking at. Current solution: send screenshots to vision models, dealing with terrible latency.</p> <p>LiveKit Vision Agents:</p> <pre><code>assistant = MultimodalAgent(\n    video=True,  # Agent can see\n    audio=True,  # Agent can hear\n    llm=openai.LLM(model=\"gpt-4o\"),\n)\n\n# Camera feed goes directly to the agent\n# User speaks, agent sees and responds\n</code></pre> <p>Gemini Live agents that can see. Vision-enabled customer support. AI assistants for virtual events that understand what's on screen. Educational apps where AI tutors watch students solve problems.</p> <p>Video, audio, and data - all in one real-time session with your AI models.</p> <p>\ud83d\udcda Vision agent example \u00b7 Multimodal capabilities</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#deploy-anywhere","title":"Deploy Anywhere","text":"<p>Replaces: Vendor lock-in, inflexible hosting</p> <p>Self-Hosted:</p> <pre><code># Install LiveKit Server (Linux)\ncurl -sSL https://get.livekit.io | bash\n\n# Run it\nlivekit-server --dev\n</code></pre> <p>Full control. Your infrastructure. Your compliance requirements. Apache 2.0 license - modify whatever you need.</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#get-started","title":"Get Started","text":"<p>Try it live: Visit kitt.livekit.io - talk to a real-time voice AI agent. Running on LiveKit. All open source. Just hit the Connect button at top-right.</p> <p>Quick Start (Python):</p> <pre><code>pip install livekit livekit-agents\n\n# Create your first voice agent\npython agent.py dev\n</code></pre> <p>Quick Start (Self-Hosted):</p> <pre><code>docker run -p 7880:7880 \\\n  -e LIVEKIT_KEYS=\"devkey: secret\" \\\n  livekit/livekit-server:latest --dev\n</code></pre> <p>10 minutes to working prototype. Zero maintenance. Unlimited possibilities.</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#real-world-examples","title":"Real-World Examples","text":"<p>Voice AI: Customer service bots that handle thousands of concurrent calls Live Shopping: Interactive auctions with millions in sales</p> <p>Computer Vision: Real-time face detection for attendance systems - process camera feeds, draw bounding boxes, stream annotated video to monitoring dashboards</p> <p>Robotics: Controlling drones or agricultural machines with real-time video and telemetry</p> <p>Education: Virtual classrooms with breakout rooms and screen sharing</p> <p>Events: Interactive livestreams with real-time Q&amp;A</p> <p>One platform. Every real-time use case.</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/2025/11/12/livekit---one-platform-real-time-everything/#resources","title":"Resources","text":"<p>\ud83d\udcd6 Documentation</p> <p>\ud83d\udcbb GitHub</p> <p>\ud83c\udf93 Free Course (DeepLearning.AI)</p> <p>\ud83d\udd27 Example Agents</p> <p>Start building: livekit.io</p>","tags":["blog","Agent framework","Real-time","Voice AI","WebRTC"]},{"location":"blog/archive/2025/11/","title":"2025/11","text":"","tags":["blog"]},{"location":"blog/category/tech-blog/","title":"Tech Blog","text":"","tags":["blog"]}]}